This study proposes a machine learning model for tracking and predicting movements in a virtual reality (VR) environment. We detect hand and body gestures using human pose estimation based on off-the-shelf optical camera images using machine learning, and obtain reliable gesture recognition without additional sensors. We then employ an avatar to prompt users to learn and use gestures to communicate. The model shows promising results, indicating the potential for enhanced user experience and improved communication in VR environments.