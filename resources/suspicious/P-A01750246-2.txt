The growing influence and decision-making capacities of Autonomous systems and Artificial Intelligence in our lives force us to consider the values embedded in these systems. But how ethics should be implemented into these systems? In this study, the solution is seen on philosophical conceptualization as a framework to form practical implementation model for ethics of AI. The first section discusses issues that may arise in the near future of AI. The second section outlines challenges for ensuring that AI operates safely as it approaches humans in its intelligence. The third section outlines how we might assess whether, and in what circumstances, AIs themselves have moral status. From that theoretical and practical basis, the study of the legal system is carried out by examining its foundations, the governance model and the regulatory bases. According to this analysis, throughout the work and in the conclusions, International Law is identified as the principal legal framework for the regulation of AI.
