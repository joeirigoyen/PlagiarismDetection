This was achieved by a carefully crafted design that allows for increasing the depth and width of the network while keeping the computational budget constant. To optimize quality, the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing. One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet, a 22 layers deep network, the quality of which is assessed in the context of classification and detection. Belief merging has received much attention from the research community with a large range of applications in Computer Science and Artificial Inteligence. In this paper, we represent a new belief merging approach for prioritized belief bases. The mean squared error (MSE), root mean squared error (RMSE), normalization root mean squared error (NRMSE), and Pearson's correlation (R) measures were used in the computation of the findings of the deep learning stock prediction models. Between the two deep learning models, the CNN-LSTM model scored slightly better (Tesla: R-squared = 98.37%; Apple: R-squared = 99.48%). The CNN-LSTM model showed a superior performance compared with the single deep learning LSTM and existing systems in predicting stock market prices.